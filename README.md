relu epoch 10 -> loss: 0.2680 - accuracy: 0.9071
swish epoch 10 -> loss: 0.8646 - accuracy: 0.6987
custom epoch 10 -> loss: 0.1428 - accuracy: 0.9499

relu
Loss: 0.9479744793534279
Accuracy: 0.796999990940094

swish
Loss: 1.6475953691482543
Accuracy: 0.5329999923706055

custom
Loss: 0.9692827097415924
Accuracy: 0.7893999814987183

By using cifar-10 as a simplpe example, relu has a accuracy since cifar-10 dataset is not as complicated as other dataset
in the future, we will compare the different on different CNN model on different datasets

Accuracy comparsion
![alt text](https://github.com/justinkwan1216/Activation_loss/blob/master/accuracy.png)

Accuracy comparsion
![alt text](https://github.com/justinkwan1216/Activation_loss/blob/master/loss.png)

custom activation function and swish graph
![alt text](https://github.com/justinkwan1216/Activation_loss/blob/master/graph.png)
